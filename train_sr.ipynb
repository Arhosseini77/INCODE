{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9452a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import argparse\n",
    "import cv2\n",
    "from scipy import io\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from pytorch_msssim import ssim\n",
    "\n",
    "from modules import utils\n",
    "from modules.models import INR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7de91a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='INCODE')\n",
    "\n",
    "# Shared Parameters\n",
    "parser.add_argument('--input',type=str, default='./incode_data/Image/0882.png', help='Input image path')\n",
    "parser.add_argument('--inr_model',type=str, default='incode', help='[gauss, mfn, relu, siren, wire, wire2d, ffn, incode]')\n",
    "parser.add_argument('--lr',type=float, default=9e-4, help='Learning rate')\n",
    "parser.add_argument('--using_schedular', type=bool, default=True, help='Whether to use schedular')\n",
    "parser.add_argument('--scheduler_b', type=float, default=0.1, help='Learning rate scheduler')\n",
    "parser.add_argument('--maxpoints', type=int, default=256*256, help='Batch size')\n",
    "parser.add_argument('--niters', type=int, default=501, help='Number if iterations')\n",
    "parser.add_argument('--steps_til_summary', type=int, default=100, help='Number of steps till summary visualization')\n",
    "parser.add_argument('--upscale_factor', type=int, default=4, help='Upscale factor for super-resolution (e.g., 4x larger output)')\n",
    "parser.add_argument('--eval_epoch', type=int, default=400, help='HR evaluation epoch')\n",
    "\n",
    "# INCODE Parameters\n",
    "parser.add_argument('--a_coef',type=float, default=0.1993, help='a coeficient')\n",
    "parser.add_argument('--b_coef',type=float, default=0.0196, help='b coeficient')\n",
    "parser.add_argument('--c_coef',type=float, default=0.0588, help='c coeficient')\n",
    "parser.add_argument('--d_coef',type=float, default=0.0269, help='d coeficient')\n",
    "\n",
    "\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c268067e",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d16c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_hr = utils.normalize(plt.imread(args.input).astype(np.float32), True)\n",
    "im_lr = cv2.resize(im_hr, None, fx=1/args.upscale_factor, fy=1/args.upscale_factor, interpolation=cv2.INTER_AREA)\n",
    "H_hr, W_hr, _ = im_hr.shape\n",
    "H_lr, W_lr, _ = im_lr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ab2563",
   "metadata": {},
   "source": [
    "## Defining Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c717b7",
   "metadata": {},
   "source": [
    "### Defining desired Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cdf32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency Encoding\n",
    "pos_encode_freq = {'type':'frequency', 'use_nyquist': True, 'mapping_input':512}\n",
    "\n",
    "# Gaussian Encoding\n",
    "pos_encode_gaus = {'type':'gaussian', 'scale_B': 10, 'mapping_input': 256}\n",
    "\n",
    "# No Encoding\n",
    "pos_encode_no = {'type': None}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c1145d",
   "metadata": {},
   "source": [
    "### Model Configureations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d602b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Harmonizer Configurations\n",
    "MLP_configs={'task': 'image',\n",
    "             'model': 'resnet34',\n",
    "             'truncated_layer':5,\n",
    "             'in_channels': 64,             \n",
    "             'hidden_channels': [64, 32, 4],\n",
    "             'mlp_bias':0.3120,\n",
    "             'activation_layer': nn.SiLU,\n",
    "             'GT': torch.tensor(im_lr).to(device)[None,...].permute(0, 3, 1, 2)\n",
    "            }\n",
    "\n",
    "### Model Configurations\n",
    "model = INR(args.inr_model).run(in_features=2,\n",
    "                                out_features=3, \n",
    "                                hidden_features=256,\n",
    "                                hidden_layers=3,\n",
    "                                first_omega_0=30.0,\n",
    "                                hidden_omega_0=30.0,\n",
    "                                pos_encode_configs=pos_encode_no, \n",
    "                                MLP_configs = MLP_configs\n",
    "                               ).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db268c3d",
   "metadata": {},
   "source": [
    "## Training Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f58b062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer setup\n",
    "if args.inr_model == 'wire':\n",
    "    args.lr = args.lr * min(1, args.maxpoints / (H * W))\n",
    "optim = torch.optim.Adam(lr=args.lr, params=model.parameters())\n",
    "scheduler = lr_scheduler.LambdaLR(optim, lambda x: args.scheduler_b ** min(x / args.niters, 1))\n",
    "\n",
    "# Initialize lists for PSNR and SSIM\n",
    "psnr_values_lr = []\n",
    "psnr_values_hr = []\n",
    "ssim_values_hr = []\n",
    "mse_array = torch.zeros(args.niters, device=device)\n",
    "\n",
    "# Initialize best loss value as positive infinity\n",
    "best_loss = torch.tensor(float('inf'))\n",
    "\n",
    "# Generate coordinate grid\n",
    "coords_lr = utils.get_coords(H_lr, W_lr, dim=2)[None, ...]\n",
    "coords_hr = utils.get_coords(H_hr, W_hr, dim=2)[None, ...]\n",
    "\n",
    "# Convert input image to a tensor and reshape\n",
    "gt_lr = torch.tensor(im_lr).reshape(H_lr * W_lr, 3)[None, ...].to(device)\n",
    "gt_hr = torch.tensor(im_hr).reshape(H_hr * W_hr, 3)[None, ...].to(device)\n",
    "\n",
    "# Initialize a tensor for reconstructed data\n",
    "rec_lr = torch.zeros_like(gt_lr)\n",
    "rec_hr = torch.zeros_like(gt_hr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a452e7cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for step in tqdm(range(args.niters)):\n",
    "    # Randomize the order of data points for each iteration\n",
    "    indices = torch.randperm(H_lr*W_lr)\n",
    "\n",
    "    # Process data points in batches\n",
    "    for b_idx in range(0, H_lr*W_lr, args.maxpoints):\n",
    "        b_indices = indices[b_idx:min(H_lr*W_lr, b_idx+args.maxpoints)]\n",
    "        b_coords = coords_lr[:, b_indices, ...].to(device)\n",
    "        b_indices = b_indices.to(device)\n",
    "        \n",
    "        # Calculate model output\n",
    "        if args.inr_model == 'incode':\n",
    "            model_output, coef = model(b_coords)  \n",
    "        else:\n",
    "            model_output = model(b_coords) \n",
    "\n",
    "        # Update the reconstructed data\n",
    "        with torch.no_grad():\n",
    "            rec_lr[:, b_indices, :] = model_output\n",
    "\n",
    "        # Calculate the output loss\n",
    "        output_loss = ((model_output - gt_lr[:, b_indices, :])**2).mean()\n",
    "        \n",
    "        if args.inr_model == 'incode':\n",
    "            # Calculate regularization loss for 'incode' model\n",
    "            a_coef, b_coef, c_coef, d_coef = coef[0]  \n",
    "            reg_loss = args.a_coef * torch.relu(-a_coef) + \\\n",
    "                       args.b_coef * torch.relu(-b_coef) + \\\n",
    "                       args.c_coef * torch.relu(-c_coef) + \\\n",
    "                       args.d_coef * torch.relu(-d_coef)\n",
    "\n",
    "            # Total loss for 'incode' model\n",
    "            loss = output_loss + reg_loss \n",
    "        else: \n",
    "            # Total loss for other models\n",
    "            loss = output_loss\n",
    "\n",
    "        # Perform backpropagation and update model parameters\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    \n",
    "    \n",
    "    # Calculate and log mean squared error (MSE) and PSNR\n",
    "    with torch.no_grad():\n",
    "        mse_array[step] = ((gt_lr - rec_lr)**2).mean().item()\n",
    "        psnr_lr = -10*torch.log10(mse_array[step])\n",
    "        psnr_values_lr.append(psnr_lr.item())\n",
    "        \n",
    "        #### HR Evaluation\n",
    "        if step > args.eval_epoch:\n",
    "            indices_hr = torch.randperm(H_hr*W_hr)\n",
    "            for b_idx in range(0, H_hr*W_hr, args.maxpoints):\n",
    "                b_indices_hr = indices_hr[b_idx:min(H_hr*W_hr, b_idx+args.maxpoints)]\n",
    "                b_coords_hr = coords_hr[:, b_indices_hr, ...].to(device)\n",
    "                b_indices_hr = b_indices_hr.to(device)\n",
    "\n",
    "                if args.inr_model == 'incode':\n",
    "                    model_eval, _ = model(b_coords_hr)  \n",
    "                else:\n",
    "                    model_eval = model(b_coords_hr) \n",
    "                    \n",
    "                rec_hr[:, b_indices_hr, :] = model_eval\n",
    "            \n",
    "            loss_hr = ((gt_hr - rec_hr)**2).mean()\n",
    "            psnr_hr = -10*torch.log10(loss_hr)\n",
    "            psnr_values_hr.append(psnr_hr.item())\n",
    "            hr_pred = rec_hr[0, ...].reshape(H_hr, W_hr, 3).detach().cpu().numpy()\n",
    "            hr_pred = (hr_pred - hr_pred.min()) / (hr_pred.max() - hr_pred.min())\n",
    "\n",
    "            # Check if the current iteration's HR image is the best so far\n",
    "            if (loss_hr < best_loss) or (step == args.eval_epoch+1):\n",
    "                best_loss = loss_hr\n",
    "                best_img_hr = hr_pred\n",
    "                best_img_lr = rec_lr[0, ...].reshape(H_lr, W_lr, 3).detach().cpu().numpy()\n",
    "                best_img_lr = (best_img_lr - best_img_lr.min()) / (best_img_lr.max() - best_img_lr.min())\n",
    "                \n",
    "                ### Plot\n",
    "                fig, axes = plt.subplots(1, 4, figsize=(9, 9))\n",
    "                subplot_info = [\n",
    "                    {'title': 'GT HR', 'image': im_hr},\n",
    "                    {'title': 'HR Image', 'image': best_img_hr},\n",
    "                    {'title': 'GT LR', 'image': im_lr},\n",
    "                    {'title': 'LR Image', 'image': best_img_lr}\n",
    "                ]\n",
    "\n",
    "                for ax, info in zip(axes, subplot_info):\n",
    "                    ax.set_title(info['title'])\n",
    "                    ax.imshow(info['image'], cmap='gray')\n",
    "                    ax.axis('off')\n",
    "                plt.show()\n",
    "\n",
    "            \n",
    "            # SSIM\n",
    "            ms_ssim_val = ssim(torch.tensor(im_hr[None,...]).permute(0, 3, 1, 2),\n",
    "                                torch.tensor(hr_pred[None, ...]).permute(0, 3, 1, 2),\n",
    "                                data_range=1, size_average=False)\n",
    "            ssim_values_hr.append(ms_ssim_val[0].item())\n",
    "            \n",
    "            # Display intermediate results at specified intervals\n",
    "            print(\"Epoch: {} | Total Loss: {:.5f} | PSNR LR: {:.4f} | PSNR HR: {:.4f} | SSIM: {:.4f}\".format(step, \n",
    "                                                                                                  mse_array[step].item(),\n",
    "                                                                                                  psnr_lr.item(),\n",
    "                                                                                                  psnr_hr.item(),\n",
    "                                                                                                  ms_ssim_val[0].item())) \n",
    "            \n",
    "        # Display intermediate results at specified intervals\n",
    "        if (step % args.steps_til_summary == 0) and step <= args.eval_epoch:\n",
    "            print(\"Epoch: {} | Total Loss: {:.5f} | PSNR LR: {:.4f}\".format(step, \n",
    "                                                                             mse_array[step].item(),\n",
    "                                                                             psnr_lr.item())) \n",
    "    \n",
    "    # Adjust learning rate using a scheduler if applicable\n",
    "    if args.using_schedular:\n",
    "        scheduler.step()\n",
    "\n",
    "        \n",
    "# Print maximum PSNR achieved during training\n",
    "print('--------------------')\n",
    "print('Max PSNR LR:', max(psnr_values_lr))\n",
    "print('Max PSNR HR:', max(psnr_values_hr))\n",
    "print('--------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86e4b9e",
   "metadata": {},
   "source": [
    "# Convergance Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dc2a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PSNR LR vs. #Epochs\n",
    "## PSNR HR vs. #Epochs\n",
    "## SSIM vs. #Epochs\n",
    "\n",
    "\n",
    "# Define the font settings\n",
    "font = {'font': 'Times New Roman', 'size': 12}\n",
    "axfont = {'family': 'Times New Roman', 'weight': 'regular', 'size': 10}\n",
    "\n",
    "# Create a figure with 3 subplots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 3))\n",
    "\n",
    "# Plot PSNR LR vs. #Epochs\n",
    "axes[0].plot(np.arange(len(psnr_values_lr[:-1])), psnr_values_lr[:-1], label=f\"{(args.inr_model).upper()}\")\n",
    "axes[0].set_xlabel('# Epochs', fontdict=font)\n",
    "axes[0].set_ylabel('PSNR (dB)', fontdict=font)\n",
    "axes[0].set_title('PSNR LR vs. #Epochs', fontdict={'family': 'Times New Roman', 'size': 12, 'weight': 'bold'})\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, color='lightgray')\n",
    "\n",
    "# Plot PSNR HR vs. #Epochs\n",
    "axes[1].plot(np.arange(len(psnr_values_hr[:-1])), psnr_values_hr[:-1], label=f\"{(args.inr_model).upper()}\", color='black')\n",
    "axes[1].set_xlabel('# Epochs', fontdict=font)\n",
    "axes[1].set_ylabel('PSNR (dB)', fontdict=font)\n",
    "axes[1].set_title('PSNR HR vs. #Epochs', fontdict={'family': 'Times New Roman', 'size': 12, 'weight': 'bold'})\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, color='lightgray')\n",
    "\n",
    "# Plot SSIM vs. #Epochs\n",
    "axes[2].plot(np.arange(len(ssim_values_hr[:-1])), ssim_values_hr[:-1], label=f\"{(args.inr_model).upper()}\", color='red')\n",
    "axes[2].set_xlabel('# Epochs', fontdict=font)\n",
    "axes[2].set_ylabel('SSIM', fontdict=font)\n",
    "axes[2].set_title('SSIM vs. #Epochs', fontdict={'family': 'Times New Roman', 'size': 12, 'weight': 'bold'})\n",
    "axes[2].legend()\n",
    "axes[2].grid(True, color='lightgray')\n",
    "\n",
    "# Adjust spacing between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
